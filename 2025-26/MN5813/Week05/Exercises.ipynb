{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Advanced Pandas (Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "_This notebook provides exercises to practice advanced Pandas techniques, building on what you learnt in Week 04. These exercises focus on practical business scenarios and are designed to be completed in approximately 90 minutes._\n",
    "\n",
    "Note: This Jupyter Notebook was originally compiled by Alex Reppel (AR) based on conversations with [ClaudeAI](https://claude.ai/) *(version 3.5 Sonnet)*. For this year's materials, further revisions were made using [Claude Code](https://www.anthropic.com/claude-code) *(Sonnet 4.5)*, including updated documentation and git commit messages.\n",
    "\n",
    "## Structure\n",
    "\n",
    "1. Data reshaping (20 minutes)\n",
    "2. Pivot tables and aggregation (20 minutes)\n",
    "3. MultiIndex operations (15 minutes)\n",
    "4. Window functions and advanced operations (20 minutes)\n",
    "5. Data cleaning and transformation (15 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set display options for better output\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Part 1: Data reshaping (20 minutes)\n",
    "\n",
    "In this section, you'll practice converting data between wide and long formats using `melt()` and `pivot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Exercise 1: Sales data reshaping\n",
    "\n",
    "You have quarterly sales data in wide format. Convert it to long format for analysis.\n",
    "\n",
    "1. Use `melt()` to convert the quarterly columns to long format\n",
    "2. Clean the `quarter` column to remove the `sales_` prefix\n",
    "3. Display the first 10 rows of the melted data\n",
    "\n",
    "Hint: Use `str.replace()` to clean the quarter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales data in wide format\n",
    "sales_wide = pd.DataFrame({\n",
    "    \"product\": [\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\"],\n",
    "    \"region\": [\"North\", \"North\", \"South\", \"South\"],\n",
    "    \"sales_Q1\": [15000, 3000, 12000, 18000],\n",
    "    \"sales_Q2\": [18000, 3500, 14000, 20000],\n",
    "    \"sales_Q3\": [16000, 3200, 13000, 19000],\n",
    "    \"sales_Q4\": [20000, 4000, 15000, 22000]\n",
    "})\n",
    "\n",
    "print(\"Wide format:\")\n",
    "print(sales_wide)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Exercise 2: Employee performance data\n",
    "\n",
    "Convert long-format employee performance data back to wide format.\n",
    "\n",
    "1. Use `pivot()` to create a wide format with employees as rows and quarters as columns\n",
    "2. Reset the index to make `employee` a regular column\n",
    "3. Calculate the average performance for each employee across all quarters\n",
    "\n",
    "Hint: Use `.mean(axis=1)` to calculate row-wise means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance data in long format\n",
    "perf_long = pd.DataFrame({\n",
    "    \"employee\": [\"Alice\", \"Alice\", \"Alice\", \"Alice\", \n",
    "                 \"Bob\", \"Bob\", \"Bob\", \"Bob\",\n",
    "                 \"Carol\", \"Carol\", \"Carol\", \"Carol\"],\n",
    "    \"quarter\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"] * 3,\n",
    "    \"score\": [4.2, 4.5, 4.3, 4.6,\n",
    "              3.8, 4.0, 4.1, 3.9,\n",
    "              4.7, 4.8, 4.6, 4.9]\n",
    "})\n",
    "\n",
    "print(\"Long format:\")\n",
    "print(perf_long)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Exercise 3: Revenue by product and region\n",
    "\n",
    "Practice the melt-pivot workflow:\n",
    "\n",
    "1. Melt the revenue data to long format\n",
    "2. Pivot it back to show products as rows and months as columns\n",
    "3. Add a column showing total revenue for each product\n",
    "\n",
    "Hint: After pivoting, use `.sum(axis=1)` to get row totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue data\n",
    "revenue_data = pd.DataFrame({\n",
    "    \"product\": [\"Widget A\", \"Widget B\", \"Widget C\"],\n",
    "    \"region\": [\"East\", \"East\", \"West\"],\n",
    "    \"Jan\": [5000, 7000, 6000],\n",
    "    \"Feb\": [5500, 7500, 6500],\n",
    "    \"Mar\": [6000, 8000, 7000]\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Part 2: Pivot tables and aggregation (20 minutes)\n",
    "\n",
    "Practice creating pivot tables and performing advanced aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### Exercise 4: Sales analysis by region and product\n",
    "\n",
    "Create a pivot table to analyse sales performance:\n",
    "\n",
    "1. Create a pivot table with `region` as rows and `product` as columns\n",
    "2. Show total sales for each region-product combination\n",
    "3. Add margins to show row and column totals\n",
    "\n",
    "Hint: Use `margins=True` and `margins_name='Total'` in `pivot_table()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales transaction data\n",
    "sales_data = pd.DataFrame({\n",
    "    \"date\": pd.date_range(\"2024-01-01\", periods=20),\n",
    "    \"region\": [\"North\", \"South\", \"East\", \"West\"] * 5,\n",
    "    \"product\": [\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\", \"Laptop\"] * 4,\n",
    "    \"sales_amount\": np.random.randint(1000, 10000, 20)\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Exercise 5: Multi-metric department analysis\n",
    "\n",
    "Create a comprehensive departmental summary:\n",
    "\n",
    "1. Use `pivot_table()` to analyse salary, performance, and project counts by department\n",
    "2. Apply different aggregation functions to each metric:\n",
    "   - Salary: mean\n",
    "   - Performance: mean, min, max\n",
    "   - Projects: sum\n",
    "3. Round the results to 2 decimal places\n",
    "\n",
    "Hint: Pass a dictionary to `aggfunc` parameter to specify different functions for different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee data\n",
    "employee_data = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Carol\", \"Dan\", \"Eve\", \"Frank\", \"Grace\", \"Henry\"],\n",
    "    \"department\": [\"Sales\", \"IT\", \"HR\", \"Sales\", \"IT\", \"HR\", \"Sales\", \"IT\"],\n",
    "    \"salary\": [50000, 65000, 55000, 52000, 68000, 57000, 54000, 70000],\n",
    "    \"performance\": [4.2, 3.8, 4.5, 4.0, 4.1, 4.3, 3.9, 4.4],\n",
    "    \"projects_completed\": [5, 8, 6, 7, 9, 5, 6, 10]\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Exercise 6: Time-based sales analysis\n",
    "\n",
    "Analyse sales trends over time:\n",
    "\n",
    "1. Create a pivot table showing average sales by product and month\n",
    "2. Identify which product has the highest average monthly sales\n",
    "3. Calculate the month-over-month growth rate for each product\n",
    "\n",
    "Hint: Use `.pct_change(axis=1)` to calculate percentage change across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly sales data\n",
    "monthly_sales = pd.DataFrame({\n",
    "    \"date\": pd.date_range(\"2024-01-01\", periods=60, freq=\"D\"),\n",
    "    \"product\": [\"Laptop\", \"Mouse\", \"Keyboard\"] * 20,\n",
    "    \"sales\": np.random.randint(5000, 20000, 60)\n",
    "})\n",
    "\n",
    "# Extract month from date\n",
    "monthly_sales[\"month\"] = monthly_sales[\"date\"].dt.to_period(\"M\")\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Part 3: MultiIndex operations (15 minutes)\n",
    "\n",
    "Work with hierarchical indices to organise and analyse multi-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Exercise 7: Creating and navigating MultiIndex\n",
    "\n",
    "Practice working with hierarchical indices:\n",
    "\n",
    "1. Create a MultiIndex DataFrame with `region` and `city` as index levels\n",
    "2. Sort the DataFrame by the index\n",
    "3. Select all data for the 'North' region using cross-section (`.xs()`)\n",
    "4. Calculate the total sales for each region\n",
    "\n",
    "Hint: Use `level=` parameter in `.xs()` to specify which index level to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional sales data\n",
    "regional_data = pd.DataFrame({\n",
    "    \"region\": [\"North\", \"North\", \"South\", \"South\", \"East\", \"East\"],\n",
    "    \"city\": [\"London\", \"Manchester\", \"Brighton\", \"Southampton\", \"Norwich\", \"Cambridge\"],\n",
    "    \"sales_Q1\": [15000, 12000, 18000, 14000, 16000, 13000],\n",
    "    \"sales_Q2\": [16000, 13000, 19000, 15000, 17000, 14000]\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Exercise 8: Stack and unstack operations\n",
    "\n",
    "Practice reshaping with `stack()` and `unstack()`:\n",
    "\n",
    "1. Set `product` and `quarter` as a MultiIndex\n",
    "2. Use `unstack()` to move `quarter` to columns\n",
    "3. Calculate the total sales for each product\n",
    "4. Use `stack()` to convert back to long format\n",
    "\n",
    "Hint: `unstack()` moves the innermost index level to columns by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarterly product sales\n",
    "product_sales = pd.DataFrame({\n",
    "    \"product\": [\"Widget A\", \"Widget A\", \"Widget A\", \"Widget A\",\n",
    "                \"Widget B\", \"Widget B\", \"Widget B\", \"Widget B\"],\n",
    "    \"quarter\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"] * 2,\n",
    "    \"sales\": [10000, 12000, 11000, 13000,\n",
    "              8000, 9000, 8500, 9500]\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Part 4: Window functions and advanced operations (20 minutes)\n",
    "\n",
    "Apply window functions and advanced transformations to analyse trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Exercise 9: Rolling averages for trend analysis\n",
    "\n",
    "Calculate rolling statistics to identify trends:\n",
    "\n",
    "1. Calculate a 7-day rolling average of daily sales\n",
    "2. Calculate a 7-day rolling standard deviation\n",
    "3. Identify days where sales are more than 2 standard deviations above the rolling mean\n",
    "\n",
    "Hint: Use `.rolling(window=7)` with `.mean()` and `.std()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily sales data\n",
    "np.random.seed(42)\n",
    "daily_sales = pd.DataFrame({\n",
    "    \"date\": pd.date_range(\"2024-01-01\", periods=30),\n",
    "    \"sales\": np.random.randint(5000, 15000, 30)\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Exercise 10: Group-wise transformations\n",
    "\n",
    "Apply transformations within groups:\n",
    "\n",
    "1. Calculate each employee's salary as a percentage of their department's total salary\n",
    "2. Calculate each employee's ranking within their department based on performance\n",
    "3. Create a column showing the department average performance\n",
    "\n",
    "Hint: Use `.transform()` to apply functions that return the same shape as the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee performance data\n",
    "employees = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Carol\", \"Dan\", \"Eve\", \"Frank\"],\n",
    "    \"department\": [\"Sales\", \"Sales\", \"IT\", \"IT\", \"HR\", \"HR\"],\n",
    "    \"salary\": [50000, 55000, 65000, 70000, 48000, 52000],\n",
    "    \"performance\": [4.2, 4.5, 3.8, 4.1, 4.6, 4.3]\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Part 5: Data cleaning and transformation (15 minutes)\n",
    "\n",
    "Practice advanced data cleaning and feature engineering techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "### Exercise 11: Binning and categorization\n",
    "\n",
    "Create meaningful categories from continuous data:\n",
    "\n",
    "1. Use `pd.cut()` to create age groups: 'Young' (< 30), 'Mid-career' (30-45), 'Senior' (> 45)\n",
    "2. Use `pd.qcut()` to create salary quartiles\n",
    "3. Create a pivot table showing the count of employees in each age group by salary quartile\n",
    "\n",
    "Hint: `pd.qcut()` creates equal-sized bins based on quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee demographics\n",
    "demographics = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Carol\", \"Dan\", \"Eve\", \"Frank\", \"Grace\", \"Henry\",\n",
    "             \"Ivy\", \"Jack\", \"Kelly\", \"Liam\"],\n",
    "    \"age\": [25, 28, 35, 42, 31, 48, 26, 39, 44, 52, 29, 36],\n",
    "    \"salary\": [45000, 52000, 68000, 85000, 58000, 92000, 47000, 72000,\n",
    "               88000, 95000, 51000, 70000]\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "### Exercise 12: Method chaining for data pipelines\n",
    "\n",
    "Create an efficient data processing pipeline using method chaining:\n",
    "\n",
    "1. Filter to include only sales above 5000\n",
    "2. Create a new column `revenue_category` based on sales:\n",
    "   - 'Low': < 7500\n",
    "   - 'Medium': 7500-12500\n",
    "   - 'High': > 12500\n",
    "3. Group by `product` and `revenue_category` and count transactions\n",
    "4. Sort by count in descending order\n",
    "\n",
    "Try to complete this in a single chained expression using `.query()`, `.assign()`, `.groupby()`, `.size()`, and `.sort_values()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction data\n",
    "transactions = pd.DataFrame({\n",
    "    \"product\": [\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\", \"Laptop\",\n",
    "                \"Mouse\", \"Keyboard\", \"Monitor\", \"Laptop\", \"Mouse\"] * 3,\n",
    "    \"sales\": [15000, 3000, 8000, 18000, 12000,\n",
    "              4000, 6000, 20000, 16000, 3500] * 3\n",
    "})\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Well done!\n",
    "\n",
    "You've completed the Week 05 exercises. These exercises have helped you practice:\n",
    "\n",
    "- Converting data between wide and long formats with `melt()` and `pivot()`\n",
    "- Creating sophisticated analyses with `pivot_table()`\n",
    "- Working with hierarchical data using MultiIndex\n",
    "- Applying window functions for trend analysis\n",
    "- Performing group-wise transformations\n",
    "- Creating categories and bins from continuous data\n",
    "- Building efficient data pipelines with method chaining\n",
    "\n",
    "Check your answers against the Solutions notebook when you're ready. Remember, there are often multiple ways to solve these problemsâ€”the Solutions show common approaches, but your solution may differ and still be correct!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}