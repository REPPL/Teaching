{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas (Introduction)\n",
    "\n",
    "_This notebook introduces Week 4's learning objectives and key concepts, building on the Python skills from Weeks 1 and 2._\n",
    "\n",
    "Note: This Jupyter Notebook was originally compiled by Alex Reppel (AR) based on conversations with [ClaudeAI](https://claude.ai/) *(version 3.5 Sonnet)*. For this year's materials, further revisions were made using [Claude Code](https://www.anthropic.com/claude-code) *(Opus 4.1)*, including updated documentation and git commit messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 overview\n",
    "\n",
    "Welcome to Week 4! This week marks a significant milestone as we move from pure Python programming to data analysis with [Pandas](https://pandas.pydata.org/). Pandas is the cornerstone library for data manipulation in Python, and mastering it is essential for your assessment tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this week, you will be able to:\n",
    "\n",
    "1. **Understand Pandas data structures** - work with Series and DataFrames confidently\n",
    "2. **Load and save data** - import data from CSV, Excel, and JSON files\n",
    "3. **Manipulate DataFrames** - filter, sort, and transform data effectively\n",
    "4. **Handle missing data** - identify and address data quality issues\n",
    "5. **Perform aggregations** - use groupby operations to summarise data\n",
    "6. **Merge datasets** - combine data from multiple sources using joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting this week's materials, ensure you're comfortable with:\n",
    "- Python data types (strings, numbers, lists, dictionaries)\n",
    "- Writing functions\n",
    "- File handling basics (from Week 1)\n",
    "- List comprehensions (from Week 2) (optional, but recommended!)\n",
    "\n",
    "## Additional learning resources\n",
    "\n",
    "### Corey Schafer's Python Pandas Tutorial Series\n",
    "\n",
    "For additional support and different perspectives on the concepts we're covering, I can't overstate how excellent Corey Schafer's YouTube series is:\n",
    "\n",
    "1. [Part 1: Installation and Loading Data](https://www.youtube.com/watch?v=ZyhVh-qRZPA) - Getting started with Pandas\n",
    "2. [Part 2: Series](https://www.youtube.com/watch?v=zmdjNSmRXF4) - Understanding Series objects\n",
    "3. [Part 3: DataFrames](https://www.youtube.com/watch?v=zmdjNSmRXF4) - Working with DataFrames\n",
    "4. [Part 4: Filtering - Using Conditionals](https://www.youtube.com/watch?v=Lw2rlcxScZY) - Boolean indexing and filtering\n",
    "5. [Part 5: Updating Rows and Columns](https://www.youtube.com/watch?v=DCDe29sIKcE) - Modifying DataFrame data\n",
    "6. [Part 6: Add/Remove Rows and Columns](https://www.youtube.com/watch?v=HQ6XO9eT-fc) - DataFrame structure manipulation\n",
    "7. [Part 7: Sorting Data](https://www.youtube.com/watch?v=T11QYVfZoD0) - Organizing your data\n",
    "8. [Part 8: Grouping and Aggregating](https://www.youtube.com/watch?v=txMdrV1Ut64) - Analyzing by groups\n",
    "9. [Part 9: Cleaning Data](https://www.youtube.com/watch?v=KdmPHEnPJPs) - Handling missing values and duplicates\n",
    "10. [Part 10: Working with Dates and Time Series](https://www.youtube.com/watch?v=UFuo7EHI8zc) - Date/time functionality\n",
    "11. [Part 11: Reading/Writing Data](https://www.youtube.com/watch?v=N6hyN6BW6ao) - File I/O operations\n",
    "\n",
    "### Official documentation\n",
    "\n",
    "- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html) - Comprehensive official documentation\n",
    "- [10 Minutes to Pandas](https://pandas.pydata.org/docs/user_guide/10min.html) - Quick overview of key functionality\n",
    "- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) - Quick reference guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Pandas?\n",
    "\n",
    "### The challenge with pure Python\n",
    "\n",
    "Imagine analysing sales data for 10,000 transactions using only Python lists and dictionaries. You'd need to write complex loops for every operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create some demo data\n",
    "\n",
    "sales_data = [\n",
    "    {\"date\": \"2023-01-01\",\n",
    "     \"product\": \"Laptop\",\n",
    "     \"amount\": 1200},\n",
    "    {\"date\": \"2023-01-02\",\n",
    "     \"product\": \"Mouse\",\n",
    "     \"amount\": 25},\n",
    "    # ... thousands more records\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2023-01-01', 'product': 'Laptop', 'amount': 1200},\n",
       " {'date': '2023-01-02', 'product': 'Mouse', 'amount': 25}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print result\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales: £1225\n"
     ]
    }
   ],
   "source": [
    "# Calculate total sales\n",
    "# Without Pandas requires manual loop\n",
    "\n",
    "total = 0\n",
    "for sale in sales_data:\n",
    "    total += sale[\"amount\"]\n",
    "print(f\"Total sales: £{total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas advantage\n",
    "\n",
    "With Pandas, the same operation becomes elegant and efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales: £1225\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(sales_data)\n",
    "total = df[\"amount\"].sum()\n",
    "print(f\"Total sales: £{total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This week's structure\n",
    "\n",
    "### Introduction (this notebook)\n",
    "- Overview of Pandas capabilities\n",
    "- Understanding when and why to use Pandas\n",
    "- Preview of key concepts\n",
    "\n",
    "### Demonstration\n",
    "- Comprehensive walkthrough of Pandas features\n",
    "- Series and DataFrame creation\n",
    "- Data loading and saving\n",
    "- Essential operations and transformations\n",
    "- Grouping and aggregation\n",
    "- Merging and joining data\n",
    "\n",
    "### Exercises (90 minutes)\n",
    "- Progressive exercises building Pandas skills\n",
    "- Real-world data scenarios\n",
    "- Focus on practical applications\n",
    "\n",
    "### Solutions\n",
    "- Complete solutions with explanations\n",
    "- Alternative approaches discussed\n",
    "- Best practices highlighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key concepts preview\n",
    "\n",
    "### 1. Series - One-dimensional data\n",
    "\n",
    "A Pandas `Series` is a one-dimensional labeled array that can hold any data type (integers, strings, floating point numbers, Python objects, etc.). Think of it as a **cross between a Python list and a dictionary** - it has the ordered nature of a list but with labels (called an index) for each element. `Series` are the building blocks of `DataFrame`s; each column in a `DataFrame` is essentially a `Series`.\n",
    "\n",
    "**Learn more**: [Corey Schafer - Python Pandas Tutorial (Part 2): Series](https://www.youtube.com/watch?v=zmdjNSmRXF4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book      10.99\n",
      "Shirt     25.50\n",
      "Coffee     5.00\n",
      "Lunch     15.75\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prices = pd.Series(\n",
    "    [10.99, 25.50, 5.00, 15.75],\n",
    "    index=[\"Book\", \"Shirt\", \"Coffee\", \"Lunch\"])\n",
    "\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average price: £14.31\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAverage price: £{prices.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DataFrame - Two-dimensional data\n",
    "\n",
    "A `DataFrame` is Pandas' **primary data structure** - a two-dimensional labeled data structure with columns that can be of different types. You can think of it as a spreadsheet, or a dictionary of `Series` objects. `DataFrames` are incredibly versatile and allow you to store and manipulate tabular data with rows and columns. Each column is a `Series`, and operations can be performed on entire columns, rows, or individual cells.\n",
    "\n",
    "**Learn more**: [Corey Schafer - Python Pandas Tutorial (Part 3): DataFrames](https://www.youtube.com/watch?v=zmdjNSmRXF4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataFrame is like a spreadsheet\n",
    "data = {\n",
    "    \"Product\": [\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\"],\n",
    "    \"Price\": [800, 25, 50, 200],\n",
    "    \"Stock\": [10, 50, 30, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Product  Price  Stock\n",
      "0    Laptop    800     10\n",
      "1     Mouse     25     50\n",
      "2  Keyboard     50     30\n",
      "3   Monitor    200     15\n"
     ]
    }
   ],
   "source": [
    "inventory = pd.DataFrame(data)\n",
    "print(inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total inventory value: £13750\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal inventory value: £{(inventory[\"Price\"] * inventory[\"Stock\"]).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data filtering and selection\n",
    "\n",
    "Filtering and selection are fundamental operations in data analysis that allow you to focus on specific subsets of your data. In Pandas, you can select data using column names, row indices, or boolean conditions. Boolean indexing (shown below) is particularly powerful - you create a condition that returns `True` or `False` for each row, and Pandas returns only the rows where the condition is `True`.\n",
    "\n",
    "This allows you to answer questions like *\"Which products cost more than £50?\" or \"Which customers made purchases last month?\"*\n",
    "\n",
    "**Learn more**: [Corey Schafer - Python Pandas Tutorial (Part 4): Filtering](https://www.youtube.com/watch?v=Lw2rlcxScZY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expensive items:\n",
      "   Product  Price  Stock\n",
      "0   Laptop    800     10\n",
      "3  Monitor    200     15\n"
     ]
    }
   ],
   "source": [
    "# Find expensive items (price > £50)\n",
    "expensive_items = inventory[inventory[\"Price\"] > 50]\n",
    "print(\"Expensive items:\")\n",
    "print(expensive_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Grouping and aggregation\n",
    "\n",
    "`GroupBy` operations follow a \"split-apply-combine\" pattern: split your data into groups based on some criteria, apply a function to each group independently, and combine the results back into a data structure. This is essential for answering questions like *\"What's the average sale per region?\"* or *\"How many products were sold by category?\"* The `groupby()` method is one of the most powerful features in Pandas, enabling you to perform complex aggregations with simple, readable code.\n",
    "\n",
    "**Learn more**: [Corey Schafer - Python Pandas Tutorial (Part 7): GroupBy and Aggregate](https://www.youtube.com/watch?v=txMdrV1Ut64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sales by category\n",
    "sales = pd.DataFrame({\n",
    "    \"Category\": [\"Electronics\", \"Electronics\", \"Office\", \"Office\", \"Office\"],\n",
    "    \"Product\": [\"Laptop\", \"Mouse\", \"Desk\", \"Chair\", \"Lamp\"],\n",
    "    \"Revenue\": [2400, 150, 500, 800, 120]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue by category:\n",
      "Category\n",
      "Electronics    2550\n",
      "Office         1420\n",
      "Name: Revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_totals = sales.groupby(\"Category\")[\"Revenue\"].sum()\n",
    "\n",
    "print(\"Revenue by category:\")\n",
    "print(category_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world applications\n",
    "\n",
    "### What you'll be able to do\n",
    "\n",
    "After this week, you'll be able to extend your group project with the following:\n",
    "\n",
    "1. **Load and clean the Olympics dataset** for your group project\n",
    "2. **Calculate statistics** like average medals per country\n",
    "3. **Filter data** to focus on specific sports or years\n",
    "4. **Merge datasets** to combine athlete and event information\n",
    "5. **Handle missing values** in real-world data\n",
    "6. **Create summary tables** for your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common challenges\n",
    "\n",
    "Based on experience, students often find these aspects challenging:\n",
    "\n",
    "1. **Index confusion** - Understanding the difference between label-based and position-based indexing\n",
    "2. **Chained operations** - Knowing when to use `loc`, `iloc`, or bracket notation\n",
    "3. **GroupBy logic** - Understanding split-apply-combine operations\n",
    "4. **Merge types** - Choosing between inner, outer, left, and right joins\n",
    "\n",
    "**We'll address each of these thoroughly in the Demonstration notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to assessment\n",
    "\n",
    "### Group project (Week 3 assessment)\n",
    "\n",
    "Pandas is essential for:\n",
    "- Loading the Olympics CSV file\n",
    "- Cleaning missing values\n",
    "- Creating calculated columns (e.g., Age_Group)\n",
    "- Aggregating medal counts by country\n",
    "- Filtering specific Olympic years or sports\n",
    "\n",
    "### Individual report\n",
    "\n",
    "You'll use Pandas to:\n",
    "- Import your chosen dataset\n",
    "- Perform data quality checks\n",
    "- Transform data for analysis\n",
    "- Generate summary statistics\n",
    "- Prepare data for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended approach\n",
    "\n",
    "1. **Review this Introduction** (10 minutes)\n",
    "   - Understand the week's objectives\n",
    "   - Run the preview examples\n",
    "\n",
    "2. **Work through the Demonstration** (90 minutes)\n",
    "   - Run every code cell\n",
    "   - Experiment with modifications\n",
    "   - Take notes on new concepts\n",
    "\n",
    "3. **Complete Exercises** (90 minutes)\n",
    "   - Start with Series exercises\n",
    "   - Progress to DataFrame operations\n",
    "   - Don't skip the file I/O exercises\n",
    "\n",
    "4. **Review Solutions** (30 minutes)\n",
    "   - Compare your approaches\n",
    "   - Note alternative methods\n",
    "   - Identify areas for practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for success\n",
    "\n",
    "### Do:\n",
    "- ✅ Experiment with small datasets first\n",
    "- ✅ Use `.head()` to preview data frequently\n",
    "- ✅ Check data types with `.dtypes`\n",
    "- ✅ Read error messages carefully\n",
    "- ✅ Keep the Pandas documentation handy\n",
    "\n",
    "### Don't:\n",
    "- ❌ Modify original DataFrames without keeping a copy\n",
    "- ❌ Ignore warnings about chained assignment\n",
    "- ❌ Assume data is clean without checking\n",
    "- ❌ Use loops when Pandas has built-in methods\n",
    "\n",
    "*(In this case, `don't` really means `don't`.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick reference\n",
    "\n",
    "Essential Pandas operations you'll use frequently (we'll cover these in the Demonstration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Loading data\ndf = pd.read_csv(\"assets/data/people_with_salary.csv\")\n\n# Viewing data\ndf.head()        # First 5 rows\ndf.info()        # Data types and missing values\ndf.describe()    # Statistical summary\n\n# Selecting data\nvalue = 30000\ndf[\"Name\"]     # Single column\ndf[[\"Name\", \"Age\"]]  # Multiple columns\ndf[df[\"Salary\"] > value]  # Filter rows\n\n# Modifying data\nvalues = [1, 2, 3, 4]\ndf[\"new_column\"] = values  # Add column\ndf.drop(\"Name\", axis=1)  # Remove column\ndf.dropna()      # Remove missing values\ndf.fillna(value) # Fill missing values\n\n# Aggregating\ndf.groupby(\"Salary\").mean(numeric_only=True)  # Group and aggregate\n# df.groupby(\"Salary\")[[\"Age\"]].mean()  # Alternatively, for \"Age\" only\n\n# Create pivot table\ndf.pivot_table(\n    values=\"Salary\",\n    index=\"City\",\n    columns=\"Country\",\n    aggfunc=\"mean\")\n\n# Showing data\nprint(df)\n\n# Saving data\ndf.to_csv(\"assets/example_data/example_output.csv\", index=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready to begin?\n",
    "\n",
    "If you're comfortable with:\n",
    "- Python basics from Week 1\n",
    "- Advanced Python from Week 2\n",
    "- The assessment requirements from Week 3\n",
    "\n",
    "Then you're ready to dive into Pandas!\n",
    "\n",
    "Remember:\n",
    "- **Pandas is a tool** - focus on what it can do, not memorising syntax\n",
    "- **Practice is essential** - work through examples actively\n",
    "- **Errors are normal** - they help you learn\n",
    "- **Documentation is your friend** - use it frequently\n",
    "\n",
    "Proceed to the Demonstration notebook when ready. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}